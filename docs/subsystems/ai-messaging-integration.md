# AI Messaging Integration with Event-Driven LangGraph Agents

This document describes the architecture and implementation of a sophisticated event-driven AI-powered messaging system that enhances mentor-student communication using LangGraph multi-agent workflows, Portkey AI gateway, and comprehensive event-based processing.

## Overview

The AI Messaging Integration feature extends Zulip's existing mentor-student communication framework with:

1. **âœ… Event-Driven AI Agent System**: **FULLY IMPLEMENTED** - LangGraph agents orchestrated through Zulip's event system for scalable, asynchronous processing
2. **âœ… AI Message Tagging**: **FULLY IMPLEMENTED** - Complete metadata tracking for AI-generated messages with database fields
3. **âœ… Intelligent Response Generation**: **FULLY IMPLEMENTED** - Multi-agent workflows that analyze mentor styles and generate contextual responses
4. **âœ… Portkey Integration**: **FULLY IMPLEMENTED** - Enterprise-grade LLM gateway with observability and error handling
5. **âœ… Comprehensive Event System**: **FULLY IMPLEMENTED** - Full event lifecycle with listeners, analytics, and monitoring
6. **ğŸ”„ LMS Data Integration**: Optional external student data for personalized educational support (configurable)

The system operates on a modern event-driven architecture that processes AI conversations asynchronously, providing better performance and scalability while maintaining all message integrity and user experience.

## Implementation Status

### âœ… Completed Features (v2.0 - Event-Driven Architecture)

#### Event-Driven AI Agent System
- **Agent Orchestrator**: `zerver/lib/ai_agent_core.py` - Complete LangGraph multi-agent workflow system
- **Event Processing**: `zerver/event_listeners/ai_mentor.py` - Asynchronous event-driven AI conversation processing
- **Agent Dispatcher**: `zerver/actions/ai_mentor_events.py` - Event creation and dispatch system for AI conversations
- **Message Integration**: `zerver/actions/message_send.py` - Seamless integration with Zulip's message sending pipeline

#### AI Message Tagging and Metadata
- **Database Fields**: Added `is_ai_generated` and `ai_metadata` fields to Message model
- **Migration**: `zerver/migrations/10003_add_ai_message_fields.py` - Database schema for AI message tracking
- **Metadata Structure**: Comprehensive JSON metadata including model, confidence, timestamps, and event tracking
- **Event Tagging**: AI messages tagged with `triggered_by_event: true` for audit trails

#### LangGraph Multi-Agent Workflows
- **Style Analysis Agent**: Analyzes mentor communication patterns using AI with caching
- **Context Analysis Agent**: Assesses message urgency, sentiment, and academic context
- **Response Generation Agent**: Creates multiple response variants with quality scoring
- **Intelligent Suggestion Agent**: Generates real-time contextual suggestions for mentors
- **Decision Agent**: Evaluates thresholds and selects optimal responses

#### Event System and Monitoring
- **Event Types**: 7 event types including new `ai_agent_conversation` event for processing triggers
- **Event Listeners**: Complete analytics, quality monitoring, error recovery, and performance tracking
- **Real-time Processing**: Asynchronous event-driven processing with immediate dispatch
- **Error Handling**: Comprehensive error recovery with event-specific error notifications

#### Portkey AI Gateway Integration
- **Enterprise LLM Access**: Multi-provider support with automatic failover
- **Observability**: Built-in request tracing, metrics, and usage analytics
- **Error Handling**: Exponential backoff, retries, and provider fallbacks
- **Cost Management**: Usage tracking, rate limiting, and budget controls

#### API Endpoints (Enhanced)
- **Event-Driven Processing**: `zerver/views/ai_mentor_messages.py` - Enhanced with agent system support
- **Intelligent Suggestions**: New endpoints for real-time AI-powered mentor suggestions
- **Agent Configuration**: Settings management for multi-agent workflows
- **Performance Monitoring**: Agent system health checks and metrics

### ğŸ”„ In Development

#### Enhanced AI Features
- Multi-modal style analysis
- Sentiment-aware responses
- Advanced natural language processing

### ğŸ“‹ Planned Features

#### LMS Data Integration
- External student data integration
- Academic context processing
- Performance-based suggestions

#### Advanced Analytics Dashboard
- Real-time mentor effectiveness metrics
- Student engagement tracking
- AI system performance monitoring

## Event-Driven Architecture

### Message Flow with Event Processing

```
Student Message â†’ Message Send Pipeline â†’ AI Agent Event Trigger
                         â†“
               ai_agent_conversation Event Created
                         â†“
            Event Listener Processes Asynchronously
                         â†“
         LangGraph Multi-Agent Workflow Execution
                         â†“
    AI Response Generated â†’ Message Tagged â†’ Event Notifications
```

**Key Benefits of Event-Driven Design:**
- **Non-blocking Performance**: Message sending is not delayed by AI processing
- **Scalable Processing**: AI workflows run asynchronously and can be distributed
- **Robust Error Handling**: Failed AI processing doesn't affect message delivery
- **Comprehensive Monitoring**: Full event trails for debugging and analytics
- **Flexible Architecture**: Easy to add new event listeners and processing logic

### Event System Integration

```python
# Message sending triggers event
def do_send_messages(send_message_requests):
    # ... existing message processing ...

    # AI Agent Integration: Trigger events for student-to-mentor messages
    for send_request in send_message_requests:
        if is_student_to_mentor_message(send_request.message):
            trigger_ai_agent_conversation(
                mentor=recipient,
                student=sender,
                original_message=content,
                original_message_id=message_id
            )

    return sent_message_results

# Event listener processes AI conversations
def handle_ai_agent_conversation(event):
    # Extract event data
    mentor = get_user_profile(event['mentor']['user_id'])
    student = get_user_profile(event['student']['user_id'])

    # Process through LangGraph agents
    ai_response = ai_agent_orchestrator.process_student_message(
        student=student,
        mentor=mentor,
        message_content=event['message_data']['content']
    )

    # Send AI response with metadata tagging
    if ai_response:
        send_ai_response_with_metadata(mentor, student, ai_response)
```

## Architecture

### Core Components (Event-Driven LangGraph Agent System)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Zulip Core System                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   User Roles    â”‚  â”‚   Realm Model    â”‚  â”‚ Messaging   â”‚ â”‚
â”‚  â”‚  - Mentors      â”‚  â”‚  - Tenant        â”‚  â”‚ - Direct    â”‚ â”‚
â”‚  â”‚  - Students     â”‚  â”‚    Isolation     â”‚  â”‚ - Streams   â”‚ â”‚
â”‚  â”‚  - Faculty      â”‚  â”‚  - Settings      â”‚  â”‚ - Topics    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              LangGraph AI Agent Orchestrator                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Style Analysis â”‚  â”‚ Context Analysis â”‚  â”‚ Response    â”‚ â”‚
â”‚  â”‚     Agent       â”‚  â”‚     Agent        â”‚  â”‚ Generation  â”‚ â”‚
â”‚  â”‚  - Pattern Recogâ”‚  â”‚ - Urgency Assess â”‚  â”‚   Agent     â”‚ â”‚
â”‚  â”‚  - Confidence   â”‚  â”‚ - Sentiment      â”‚  â”‚ - Multiple  â”‚ â”‚
â”‚  â”‚  - Vocabulary   â”‚  â”‚ - Academic Focus â”‚  â”‚   Variants  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Intelligent     â”‚  â”‚ Decision Making  â”‚  â”‚ Workflow    â”‚ â”‚
â”‚  â”‚ Suggestion      â”‚  â”‚     Agent        â”‚  â”‚ Management  â”‚ â”‚
â”‚  â”‚   Agent         â”‚  â”‚ - Auto-Response  â”‚  â”‚ - State     â”‚ â”‚
â”‚  â”‚ - Real-time     â”‚  â”‚ - Thresholds     â”‚  â”‚ - Persistenceâ”‚ â”‚
â”‚  â”‚ - Contextual    â”‚  â”‚ - Quality Score  â”‚  â”‚ - Recovery  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Portkey AI Gateway Layer                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   LLM Gateway   â”‚  â”‚  Observability   â”‚  â”‚ Error       â”‚ â”‚
â”‚  â”‚  - OpenAI       â”‚  â”‚  - Metrics       â”‚  â”‚ Handling    â”‚ â”‚
â”‚  â”‚  - Anthropic    â”‚  â”‚  - Tracing       â”‚  â”‚ - Retries   â”‚ â”‚
â”‚  â”‚  - Others       â”‚  â”‚  - Usage Stats   â”‚  â”‚ - Fallbacks â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Cache Layer    â”‚  â”‚ Rate Limiting    â”‚  â”‚ Security    â”‚ â”‚
â”‚  â”‚  - Semantic     â”‚  â”‚ - Per User       â”‚  â”‚ - API Keys  â”‚ â”‚
â”‚  â”‚  - Response     â”‚  â”‚ - Per Model      â”‚  â”‚ - Access    â”‚ â”‚
â”‚  â”‚  - Style Data   â”‚  â”‚ - Cost Control   â”‚  â”‚ - Audit     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Legacy System (Fallback) + Extensions           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Template-Based  â”‚  â”‚   LMS Database   â”‚  â”‚  Analytics  â”‚ â”‚
â”‚  â”‚   AI System     â”‚  â”‚   (Read-Only)    â”‚  â”‚  Platform   â”‚ â”‚
â”‚  â”‚ - Style Rules   â”‚  â”‚ - Student Data   â”‚  â”‚ - Usage     â”‚ â”‚
â”‚  â”‚ - Decision Tree â”‚  â”‚ - Course Info    â”‚  â”‚ - Performanceâ”‚ â”‚
â”‚  â”‚ - Basic Responsesâ”‚  â”‚ - Performance   â”‚  â”‚ - Quality   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Key Features

### 1. LangGraph Multi-Agent System ğŸ†• NEW

**Advanced AI Agent Orchestration:**

**STATUS**: âœ… **FULLY IMPLEMENTED** - Production-ready multi-agent workflow system

The LangGraph Agent System represents a significant advancement over the template-based approach, featuring:

- **Specialized Agents**: Five specialized agents each handling specific aspects of AI mentor responses
- **State Management**: Persistent state across agent interactions with SQLite checkpointing
- **Workflow Orchestration**: Complex decision trees and conditional routing between agents
- **Error Recovery**: Robust error handling with automatic fallbacks to legacy system
- **Performance Monitoring**: Built-in metrics collection and observability

**Agent Workflow Architecture:**

```python
# LangGraph workflow execution
Student Message â†’ Style Analysis Agent â†’ Context Analysis Agent
                       â†“                         â†“
              Response Generation Agent â† Intelligent Suggestion Agent
                       â†“
              Decision Making Agent â†’ Auto-Response Decision
                       â†“
              Final Response + Suggestions
```

**Individual Agent Capabilities:**

1. **Style Analysis Agent** (`MentorStyleAgent`)
   - Analyzes mentor communication patterns using AI
   - Extracts tone, vocabulary, teaching approach, and structure preferences
   - Calculates confidence scores based on data quality
   - Caches analysis results for performance

2. **Context Analysis Agent** (`ContextAnalysisAgent`)
   - Assesses message urgency on 0-1 scale
   - Analyzes conversation sentiment and academic context
   - Identifies time-sensitive indicators
   - Provides comprehensive context for decision making

3. **Response Generation Agent** (`ResponseGenerationAgent`)
   - Generates multiple response variants (supportive, questioning, informative)
   - Applies mentor style patterns to ensure authenticity
   - Uses varied temperature settings for response diversity
   - Includes quality assessment for each generated response

4. **Intelligent Suggestion Agent** (`IntelligentSuggestionAgent`)
   - Creates real-time suggestions for mentors
   - Categorizes suggestions (resource sharing, questioning, encouragement)
   - Provides priority levels and actionable recommendations
   - Supports multiple suggestion types simultaneously

5. **Decision Agent** (`DecisionAgent`)
   - Evaluates all decision factors for auto-response triggering
   - Applies configurable thresholds and business rules
   - Selects best response from candidates
   - Adds appropriate AI disclaimers

**Key Implementation Details:**
- **Location**: `zerver/lib/ai_agent_core.py` - Complete LangGraph implementation
- **State Management**: SQLite-based checkpointing with configurable persistence
- **Error Handling**: Graceful degradation with automatic fallback to legacy system
- **Performance**: <3 second response generation with parallel agent processing

### 2. Portkey AI Integration ğŸ†• NEW

**Enterprise-Grade LLM Gateway:**

**STATUS**: âœ… **FULLY IMPLEMENTED** - Production-ready AI infrastructure

Portkey provides robust LLM integration with advanced features:

- **Multi-Provider Support**: OpenAI, Anthropic, Google, Cohere, and others through single API
- **Built-in Observability**: Request tracing, performance metrics, and usage analytics
- **Error Handling**: Automatic retries, exponential backoff, and provider fallbacks
- **Cost Management**: Usage tracking, rate limiting, and budget controls
- **Security**: API key management, access controls, and audit logging

**Key Benefits:**

```python
# Robust LLM calls with automatic error handling
class PortkeyLLMClient:
    def chat_completion(self, messages, **kwargs):
        for attempt in range(self.config.max_retries):
            try:
                response = self.client.chat.completions.create(...)
                return {"success": True, "response": response}
            except Exception as e:
                if attempt == max_retries - 1:
                    return {"success": False, "error": str(e)}
                # Exponential backoff with jitter
                time.sleep((2 ** attempt) + random())
```

**Configuration Features:**
- **Flexible Model Selection**: Configure different models per use case
- **Performance Tuning**: Adjustable timeouts, retries, and temperature settings
- **Monitoring**: Real-time metrics and alerting for production deployment
- **Cost Optimization**: Semantic caching and intelligent routing

### 3. Hybrid Architecture System ğŸ†• NEW

**Seamless Fallback Mechanism:**

The system features a sophisticated hybrid approach that provides both cutting-edge AI capabilities and reliable fallback:

```python
def process_student_message(self, student, mentor, message_content):
    # Try LangGraph agents first
    if self.use_agents and self.agent_orchestrator:
        return self._process_with_agents(student, mentor, message_content)
    else:
        # Fallback to proven legacy system
        return self._process_with_legacy(student, mentor, message_content)
```

**Benefits:**
- **Reliability**: Always has a working fallback system
- **Gradual Rollout**: Can enable agents for specific users or realms
- **Performance**: Legacy system provides fast responses if agents fail
- **Migration**: Smooth transition from old to new system

### 4. AI Auto-Reply System âœ… ENHANCED

**Automated Mentor Response Mimicking:**

**STATUS**: âœ… **FULLY IMPLEMENTED** - Production-ready AI mentor response system

The AI Mentor Response System is now fully operational with the following capabilities:

- **Mentor Style Analysis**: Automatically analyzes communication patterns from message history
- **Selective Triggering**: Only responds when specific conditions are met to preserve human touch
- **Real-time Event System**: Complete integration with Zulip's event system for monitoring and analytics
- **Quality Control**: Confidence scoring and manual review flagging for low-confidence responses

**Key Implementation Details:**
- **Location**: `zerver/lib/ai_mentor_response.py` - Complete implementation
- **API Endpoints**: `zerver/views/ai_mentor_messages.py` - REST API access
- **Event System**: `zerver/actions/ai_mentor_events.py` - Event tracking and notifications
- **Documentation**: `docs/subsystems/ai-mentor-response-system.md` - Complete technical documentation

When a student messages a mentor and the mentor doesn't respond within a configurable time period (default: 4 hours), the AI system can automatically generate a response that mimics the mentor's communication style.

```python
# AI Auto-Reply Workflow
class AIAutoReplyEngine:
    def __init__(self):
        self.response_delay_threshold = {
            'business_hours': 4 * 3600,  # 4 hours in seconds
            'non_business_hours': 12 * 3600,  # 12 hours in seconds
            'weekend': 24 * 3600  # 24 hours in seconds
        }

    def should_trigger_auto_reply(self, message: Message, mentor: UserProfile) -> bool:
        """Determine if AI should auto-reply for unavailable mentor"""

        # Check if mentor has been inactive
        time_since_message = timezone_now() - message.date_sent
        threshold = self.get_response_threshold(message.date_sent)

        if time_since_message < timedelta(seconds=threshold):
            return False

        # Check if mentor is active but not responding
        if self.is_mentor_recently_active(mentor, hours=2):
            return False  # Mentor is online, let them respond

        # Check mentor's auto-reply preferences
        if not mentor.ai_auto_reply_enabled:
            return False

        return True

    def generate_mentor_style_response(
        self,
        student_message: str,
        mentor: UserProfile,
        conversation_history: List[Message],
        student_context: Dict
    ) -> str:
        """Generate response mimicking mentor's style"""

        # Analyze mentor's communication patterns
        mentor_style = self.analyze_mentor_communication_style(
            mentor, conversation_history
        )

        # Build context-aware prompt
        prompt = self.build_mentor_mimicking_prompt(
            student_message=student_message,
            mentor_style=mentor_style,
            student_context=student_context,
            conversation_history=conversation_history[-10:]  # Last 10 messages
        )

        # Generate AI response
        ai_response = self.get_ai_response(prompt, temperature=0.7)

        # Add mentor-style markers
        response = self.apply_mentor_style_formatting(ai_response, mentor_style)

        # Add disclaimer
        disclaimer = "\n\n*[This is an AI-generated response. Your mentor will respond personally when available.]*"

        return response + disclaimer

class MentorStyleAnalyzer:
    """Analyze and model mentor communication patterns"""

    def analyze_mentor_communication_style(
        self,
        mentor: UserProfile,
        conversation_history: List[Message]
    ) -> Dict:
        """Extract mentor's communication style from message history"""

        mentor_messages = [
            msg for msg in conversation_history
            if msg.sender == mentor
        ]

        if len(mentor_messages) < 5:
            # Not enough data, use default supportive style
            return self.get_default_mentor_style()

        style_analysis = {
            'tone': self.analyze_tone(mentor_messages),
            'formality_level': self.analyze_formality(mentor_messages),
            'response_length': self.analyze_response_length(mentor_messages),
            'common_phrases': self.extract_common_phrases(mentor_messages),
            'question_patterns': self.analyze_question_patterns(mentor_messages),
            'encouragement_style': self.analyze_encouragement_style(mentor_messages),
            'technical_language_use': self.analyze_technical_language(mentor_messages)
        }

        return style_analysis

    def analyze_tone(self, messages: List[Message]) -> str:
        """Analyze emotional tone of mentor messages"""
        # Use sentiment analysis on mentor messages
        tones = []
        for msg in messages:
            tone = self.sentiment_analyzer.analyze(msg.content)
            tones.append(tone)

        avg_positivity = sum(t['positivity'] for t in tones) / len(tones)
        avg_formality = sum(t['formality'] for t in tones) / len(tones)

        if avg_positivity > 0.7 and avg_formality < 0.5:
            return 'friendly_encouraging'
        elif avg_positivity > 0.5 and avg_formality > 0.7:
            return 'professional_supportive'
        elif avg_formality > 0.8:
            return 'formal_academic'
        else:
            return 'casual_supportive'

    def extract_common_phrases(self, messages: List[Message]) -> List[str]:
        """Extract frequently used phrases by mentor"""
        all_text = ' '.join(msg.content for msg in messages)

        # Extract common 2-4 word phrases
        common_phrases = []
        # Implementation would use NLP to find repeated patterns

        return common_phrases[:10]  # Top 10 most common phrases
```

### 2. Intelligent Message Suggestions

**Real-time AI Suggestions for Mentors:**

When mentors are composing messages, the system provides intelligent suggestions based on the student's previous messages, LMS data, and conversation context.

```python
class IntelligentSuggestionEngine:
    """Generate contextual message suggestions for mentors"""

    def get_message_suggestions(
        self,
        mentor: UserProfile,
        student: UserProfile,
        current_draft: str,
        conversation_history: List[Message],
        student_lms_data: Dict
    ) -> List[Dict]:
        """Generate intelligent message suggestions"""

        # Analyze student's recent messages and needs
        student_analysis = self.analyze_student_context(
            student, conversation_history, student_lms_data
        )

        # Generate different types of suggestions
        suggestions = []

        # 1. Academic Support Suggestions
        if student_analysis['needs_academic_help']:
            academic_suggestions = self.generate_academic_support_suggestions(
                student_analysis, student_lms_data
            )
            suggestions.extend(academic_suggestions)

        # 2. Motivational Suggestions
        if student_analysis['sentiment'] == 'struggling':
            motivational_suggestions = self.generate_motivational_suggestions(
                student_analysis
            )
            suggestions.extend(motivational_suggestions)

        # 3. Resource Suggestions
        resource_suggestions = self.generate_resource_suggestions(
            student_lms_data, student_analysis
        )
        suggestions.extend(resource_suggestions)

        # 4. Schedule/Meeting Suggestions
        if student_analysis['needs_meeting']:
            meeting_suggestions = self.generate_meeting_suggestions(
                mentor, student, student_analysis
            )
            suggestions.extend(meeting_suggestions)

        return suggestions[:5]  # Top 5 suggestions

    def analyze_student_context(
        self,
        student: UserProfile,
        conversation_history: List[Message],
        lms_data: Dict
    ) -> Dict:
        """Analyze student's current context and needs"""

        recent_student_messages = [
            msg for msg in conversation_history[-10:]
            if msg.sender == student
        ]

        analysis = {
            'sentiment': self.analyze_student_sentiment(recent_student_messages),
            'academic_performance': self.analyze_academic_performance(lms_data),
            'engagement_level': self.analyze_engagement_level(recent_student_messages),
            'specific_subjects': self.extract_subject_mentions(recent_student_messages),
            'question_types': self.classify_question_types(recent_student_messages),
            'needs_academic_help': self.detect_help_requests(recent_student_messages),
            'needs_meeting': self.detect_meeting_requests(recent_student_messages),
            'time_urgency': self.assess_urgency(recent_student_messages)
        }

        return analysis

    def generate_academic_support_suggestions(
        self,
        student_analysis: Dict,
        lms_data: Dict
    ) -> List[Dict]:
        """Generate academic support message suggestions"""

        suggestions = []

        # Based on struggling subjects
        struggling_subjects = lms_data.get('struggling_areas', [])
        for subject in struggling_subjects:
            suggestions.append({
                'type': 'academic_support',
                'priority': 'high',
                'template': f"I see you're working through some challenges with {subject}. "
                           f"Let's break this down together. What specific part is giving you trouble?",
                'reasoning': f"Student struggling with {subject} based on LMS data",
                'suggested_resources': self.get_subject_resources(subject)
            })

        # Based on recent assignment performance
        recent_grades = lms_data.get('recent_assignments', [])
        low_performing = [a for a in recent_grades if a.get('score', 100) < 70]

        if low_performing:
            latest_assignment = low_performing[0]
            suggestions.append({
                'type': 'performance_support',
                'priority': 'high',
                'template': f"I noticed your recent {latest_assignment['name']} score. "
                           f"This is a great learning opportunity. Would you like to review it together?",
                'reasoning': 'Recent assignment performance below expectations',
                'follow_up_actions': ['schedule_review_session', 'provide_additional_resources']
            })

        return suggestions

    def generate_motivational_suggestions(self, student_analysis: Dict) -> List[Dict]:
        """Generate motivational message suggestions"""

        suggestions = []
        sentiment = student_analysis['sentiment']

        if sentiment == 'frustrated':
            suggestions.append({
                'type': 'encouragement',
                'priority': 'high',
                'template': "I can sense you're feeling frustrated, and that's completely normal. "
                           "Remember, struggling with challenging material is part of the learning process. "
                           "You've overcome difficulties before, and I'm here to help you through this.",
                'reasoning': 'Student expressing frustration in recent messages'
            })

        elif sentiment == 'overwhelmed':
            suggestions.append({
                'type': 'stress_management',
                'priority': 'high',
                'template': "It sounds like you have a lot on your plate right now. "
                           "Let's prioritize what's most important and tackle things one step at a time. "
                           "What feels like the most urgent task to you?",
                'reasoning': 'Student appears overwhelmed based on message analysis'
            })

        return suggestions
```

### 3. Enhanced Context Processing

**Advanced LMS Data Integration for AI:**

```python
class AdvancedContextProcessor:
    """Process complex student context for AI responses"""

    def build_comprehensive_context(
        self,
        student: UserProfile,
        conversation_history: List[Message],
        lms_data: Dict
    ) -> Dict:
        """Build comprehensive context for AI processing"""

        context = {
            'student_profile': {
                'learning_style': lms_data.get('learning_style', 'unknown'),
                'academic_level': lms_data.get('academic_level', 'undergraduate'),
                'major': lms_data.get('major', 'unknown'),
                'year': lms_data.get('academic_year', 'unknown')
            },
            'current_academic_status': {
                'enrolled_courses': lms_data.get('current_courses', []),
                'recent_assignments': lms_data.get('recent_assignments', []),
                'upcoming_deadlines': lms_data.get('upcoming_deadlines', []),
                'current_gpa': lms_data.get('current_gpa', None),
                'credit_hours': lms_data.get('credit_hours', 0)
            },
            'conversation_context': {
                'recent_topics': self.extract_conversation_topics(conversation_history),
                'question_history': self.extract_question_patterns(conversation_history),
                'mentor_responses': self.analyze_mentor_response_patterns(conversation_history),
                'conversation_sentiment_trend': self.analyze_sentiment_trend(conversation_history)
            },
            'temporal_context': {
                'current_semester_week': self.get_current_semester_week(lms_data),
                'time_until_finals': self.get_time_until_finals(lms_data),
                'recent_activity_level': self.analyze_recent_activity(conversation_history)
            }
        }

        return context
```

### 4. Role-Based Communication Enhancement

Building on Zulip's existing role system:

```python
# Existing roles in Zulip
ROLE_MENTOR = 580
ROLE_STUDENT = 500
ROLE_FACULTY = 450
ROLE_PARENT = 550

# Enhanced communication matrix with AI
communication_matrix = {
    'mentor_to_student': {
        'ai_enhancement': True,
        'lms_context': True,
        'suggestions': ['study_resources', 'schedule_meeting', 'performance_insights']
    },
    'student_to_mentor': {
        'ai_enhancement': True,
        'lms_context': True,
        'suggestions': ['clarify_question', 'request_help', 'progress_update']
    },
    'faculty_to_student': {
        'ai_enhancement': True,
        'lms_context': True,
        'suggestions': ['assignment_feedback', 'course_guidance', 'academic_planning']
    }
}
```

### 2. LMS Data Integration

**External Database Connection (Read-Only):**

```python
# zerver/lib/lms_integration.py
import psycopg2
from django.conf import settings
from typing import Dict, Optional

class LMSDataFetcher:
    """Secure read-only access to external LMS database"""

    def __init__(self):
        self.connection_config = settings.LMS_DATABASE_CONFIG

    def get_student_context(self, user_id: int, realm_id: int) -> Optional[Dict]:
        """
        Fetch student context from LMS with strict realm isolation

        Args:
            user_id: Zulip user ID
            realm_id: Zulip realm ID for security isolation

        Returns:
            Student context data or None if not found/unauthorized
        """
        try:
            with psycopg2.connect(**self.connection_config) as conn:
                with conn.cursor() as cur:
                    # Query with security checks
                    query = """
                    SELECT
                        s.student_id,
                        s.current_courses,
                        s.recent_assignments,
                        s.performance_metrics,
                        s.learning_preferences,
                        s.last_activity
                    FROM lms_students s
                    JOIN realm_student_mapping rsm ON s.student_id = rsm.lms_student_id
                    WHERE rsm.zulip_user_id = %s
                    AND rsm.zulip_realm_id = %s
                    AND s.data_sharing_consent = true
                    """

                    cur.execute(query, (user_id, realm_id))
                    result = cur.fetchone()

                    if result:
                        return self._transform_lms_data(result)
                    return None

        except Exception as e:
            # Log error but don't expose details
            logger.error(f"LMS data fetch failed for user {user_id}: {str(e)}")
            return None

    def _transform_lms_data(self, raw_data) -> Dict:
        """Transform LMS data to Zulip-compatible format"""
        return {
            'academic_status': {
                'current_courses': raw_data['current_courses'],
                'recent_assignments': raw_data['recent_assignments'],
                'performance_summary': raw_data['performance_metrics']
            },
            'learning_profile': {
                'preferred_style': raw_data['learning_preferences'],
                'struggling_areas': self._identify_struggling_areas(raw_data),
                'strong_areas': self._identify_strong_areas(raw_data)
            },
            'engagement_metrics': {
                'last_activity': raw_data['last_activity'],
                'participation_level': self._calculate_participation(raw_data)
            }
        }
```

### 3. AI Message Enhancement Engine

```python
# zerver/lib/ai_messaging.py
from typing import Dict, Optional
import openai
from django.conf import settings
from zerver.models import UserProfile

class AIMessageEnhancer:
    """AI-powered message enhancement for educational context"""

    def __init__(self):
        self.client = openai.OpenAI(api_key=settings.OPENAI_API_KEY)
        self.content_filter = ContentFilter()

    def enhance_mentor_message(
        self,
        sender: UserProfile,
        recipient: UserProfile,
        original_content: str,
        lms_context: Optional[Dict] = None
    ) -> Dict:
        """
        Enhance mentor messages with AI-generated suggestions and context

        Args:
            sender: Mentor user profile
            recipient: Student user profile
            original_content: Original message text
            lms_context: Student's LMS data context

        Returns:
            Enhanced message with AI suggestions
        """

        # Build AI prompt with educational context
        prompt = self._build_educational_prompt(
            sender_role=sender.get_role_name(),
            recipient_role=recipient.get_role_name(),
            original_message=original_content,
            student_context=lms_context
        )

        try:
            # Call AI service
            response = self.client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {
                        "role": "system",
                        "content": self._get_system_prompt()
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=500,
                temperature=0.7
            )

            ai_content = response.choices[0].message.content

            # Apply content filtering
            filtered_content = self.content_filter.filter_educational_content(ai_content)

            # Extract suggestions and enhancements
            enhancement = self._parse_ai_response(filtered_content)

            # Log interaction for audit
            self._log_ai_interaction(sender, recipient, original_content, enhancement)

            return enhancement

        except Exception as e:
            logger.error(f"AI enhancement failed: {str(e)}")
            # Fallback to original message
            return {
                'enhanced_message': original_content,
                'suggestions': [],
                'confidence': 0.0,
                'ai_used': False
            }

    def _build_educational_prompt(self, sender_role: str, recipient_role: str,
                                original_message: str, student_context: Optional[Dict]) -> str:
        """Build contextual prompt for AI enhancement"""

        context_info = ""
        if student_context:
            context_info = f"""
            Student Context:
            - Current Courses: {student_context.get('academic_status', {}).get('current_courses', [])}
            - Recent Performance: {student_context.get('academic_status', {}).get('performance_summary', {})}
            - Learning Style: {student_context.get('learning_profile', {}).get('preferred_style', 'unknown')}
            - Areas needing support: {student_context.get('learning_profile', {}).get('struggling_areas', [])}
            """

        return f"""
        You are an AI assistant helping enhance educational communication between a {sender_role} and a {recipient_role}.

        Original Message: "{original_message}"

        {context_info}

        Please enhance this message to be more helpful and educational by:
        1. Adding relevant context or suggestions based on the student's academic status
        2. Suggesting specific resources or next steps
        3. Maintaining an encouraging and supportive tone
        4. Keeping the enhancement concise and actionable

        Respond with:
        - Enhanced message text
        - 2-3 specific suggestions for follow-up actions
        - Confidence score (0-1) for the enhancement quality
        """

    def _get_system_prompt(self) -> str:
        """System prompt for AI educational assistant"""
        return """
        You are an educational AI assistant designed to enhance communication between mentors and students.

        Guidelines:
        - Always maintain a supportive, encouraging tone
        - Provide specific, actionable suggestions
        - Respect student privacy and confidentiality
        - Focus on educational growth and learning outcomes
        - Avoid any content that could be harmful or inappropriate
        - Base suggestions on educational best practices

        Remember: Your role is to facilitate better educational communication, not to replace human judgment.
        """

class ContentFilter:
    """Filter AI content for educational appropriateness"""

    def filter_educational_content(self, content: str) -> str:
        """Apply educational content filters"""

        # Remove potentially harmful content
        filtered = self._remove_harmful_content(content)

        # Ensure educational appropriateness
        filtered = self._ensure_educational_tone(filtered)

        # Validate against educational guidelines
        if not self._is_educational_appropriate(filtered):
            # Fallback to safe default
            return "I'd be happy to help you with your studies. Please let me know if you have any specific questions."

        return filtered

    def _is_educational_appropriate(self, content: str) -> bool:
        """Check if content meets educational standards"""

        # List of inappropriate patterns
        inappropriate_patterns = [
            r'inappropriate content pattern 1',
            r'inappropriate content pattern 2',
            # Add more patterns as needed
        ]

        import re
        for pattern in inappropriate_patterns:
            if re.search(pattern, content, re.IGNORECASE):
                return False

        return True
```

### 4. Privacy and Security Framework

```python
# zerver/lib/ai_privacy.py
from zerver.models import UserProfile, Realm
from typing import Dict, Optional

class AIPrivacyController:
    """Enforce privacy and security for AI messaging features"""

    def can_access_ai_features(self, user: UserProfile) -> bool:
        """Check if user can access AI features"""

        # Check user preferences
        if user.hide_ai_features:
            return False

        # Check realm settings
        if not user.realm.ai_features_enabled:
            return False

        # Check plan permissions
        if not self._plan_supports_ai(user.realm):
            return False

        return True

    def can_access_lms_data(self, user: UserProfile, target_user: UserProfile) -> bool:
        """Check if user can access LMS data for target user"""

        # Must be same realm
        if user.realm != target_user.realm:
            return False

        # Check role permissions
        if not self._role_can_access_lms_data(user.role, target_user.role):
            return False

        # Check consent
        if not self._has_data_sharing_consent(target_user):
            return False

        return True

    def sanitize_ai_context(self, context: Dict, requesting_user: UserProfile) -> Dict:
        """Remove sensitive information from AI context"""

        sanitized = context.copy()

        # Remove PII if not authorized
        if not requesting_user.can_view_personal_info():
            sanitized.pop('personal_details', None)
            sanitized.pop('contact_info', None)

        # Remove sensitive academic data if not mentor/faculty
        if not requesting_user.is_mentor and not requesting_user.is_faculty:
            sanitized.pop('detailed_grades', None)
            sanitized.pop('disciplinary_records', None)

        return sanitized

class AIAuditLogger:
    """Audit logging for AI interactions"""

    @staticmethod
    def log_ai_interaction(
        user: UserProfile,
        action: str,
        original_content: str,
        ai_enhanced_content: str,
        context: Dict
    ):
        """Log AI interaction for audit purposes"""

        from zerver.models import RealmAuditLog

        RealmAuditLog.objects.create(
            realm=user.realm,
            acting_user=user,
            event_type=RealmAuditLog.AI_MESSAGE_ENHANCEMENT,
            event_time=timezone_now(),
            extra_data={
                'action': action,
                'original_message_length': len(original_content),
                'ai_enhanced_length': len(ai_enhanced_content),
                'lms_data_used': context.get('lms_data_used', False),
                'ai_model_used': context.get('ai_model', 'unknown'),
                'confidence_score': context.get('confidence', 0.0)
            }
        )
```

### 5. Database Schema Extensions

```python
# zerver/models/ai_messaging.py
from django.db import models
from zerver.models import UserProfile, Realm

class AIMessageEnhancement(models.Model):
    """Track AI-enhanced messages"""

    realm = models.ForeignKey(Realm, on_delete=models.CASCADE)
    sender = models.ForeignKey(UserProfile, on_delete=models.CASCADE, related_name='ai_sent_messages')
    recipient = models.ForeignKey(UserProfile, on_delete=models.CASCADE, related_name='ai_received_messages')

    original_message_id = models.BigIntegerField()  # Reference to original message
    original_content_hash = models.CharField(max_length=64)  # For integrity checking

    ai_model_used = models.CharField(max_length=100)
    enhancement_type = models.CharField(max_length=50)  # 'context_addition', 'tone_adjustment', etc.
    confidence_score = models.FloatField()

    lms_data_used = models.BooleanField(default=False)
    lms_data_sources = models.JSONField(default=list)  # Which LMS data was accessed

    created_at = models.DateTimeField(auto_now_add=True)

    class Meta:
        db_table = 'zerver_ai_message_enhancement'

class AIAutoReply(models.Model):
    """Track AI auto-replies sent on behalf of mentors"""

    realm = models.ForeignKey(Realm, on_delete=models.CASCADE)
    original_message = models.ForeignKey('zerver.Message', on_delete=models.CASCADE, related_name='ai_auto_replies')
    mentor = models.ForeignKey(UserProfile, on_delete=models.CASCADE, related_name='ai_auto_replies_sent')
    student = models.ForeignKey(UserProfile, on_delete=models.CASCADE, related_name='ai_auto_replies_received')

    # AI Response Details
    ai_response_content = models.TextField()
    mentor_style_used = models.JSONField()  # Style analysis used for mimicking
    response_delay_hours = models.FloatField()  # Hours between student message and AI reply

    # Mentor Communication Style Analysis
    mentor_messages_analyzed = models.IntegerField()  # Number of mentor messages used for style
    style_confidence_score = models.FloatField()  # Confidence in style mimicking

    # Student Context Used
    student_lms_context = models.JSONField(default=dict)
    conversation_history_length = models.IntegerField()

    # Response Metadata
    ai_model_used = models.CharField(max_length=100)
    response_generation_time_ms = models.IntegerField()

    # Disclaimer and Transparency
    disclaimer_shown = models.BooleanField(default=True)
    mentor_notified = models.BooleanField(default=False)  # Whether mentor was notified of auto-reply

    created_at = models.DateTimeField(auto_now_add=True)

    class Meta:
        db_table = 'zerver_ai_auto_reply'

class MentorCommunicationStyle(models.Model):
    """Store analyzed communication styles for mentors"""

    realm = models.ForeignKey(Realm, on_delete=models.CASCADE)
    mentor = models.OneToOneField(UserProfile, on_delete=models.CASCADE, related_name='communication_style')

    # Style Analysis Results
    tone_analysis = models.JSONField()  # friendly_encouraging, professional_supportive, etc.
    formality_level = models.FloatField()  # 0.0 (very casual) to 1.0 (very formal)
    average_response_length = models.IntegerField()  # Average word count
    common_phrases = models.JSONField(default=list)  # Frequently used phrases
    question_patterns = models.JSONField(default=list)  # How mentor asks questions
    encouragement_style = models.JSONField()  # How mentor provides encouragement
    technical_language_use = models.FloatField()  # Use of technical/academic terms

    # Analysis Metadata
    messages_analyzed_count = models.IntegerField()
    last_analysis_date = models.DateTimeField(auto_now=True)
    style_confidence_score = models.FloatField()  # Overall confidence in analysis

    # Style Evolution Tracking
    style_version = models.IntegerField(default=1)  # Version number for style updates

    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)

    class Meta:
        db_table = 'zerver_mentor_communication_style'

class AIMessageSuggestion(models.Model):
    """Track AI message suggestions provided to mentors"""

    realm = models.ForeignKey(Realm, on_delete=models.CASCADE)
    mentor = models.ForeignKey(UserProfile, on_delete=models.CASCADE, related_name='ai_suggestions_received')
    student = models.ForeignKey(UserProfile, on_delete=models.CASCADE, related_name='ai_suggestions_about')

    # Suggestion Details
    suggestion_type = models.CharField(max_length=50)  # 'academic_support', 'encouragement', etc.
    suggestion_text = models.TextField()
    priority_level = models.CharField(max_length=20)  # 'high', 'medium', 'low'
    reasoning = models.TextField()  # Why this suggestion was made

    # Context Used
    student_context_used = models.JSONField()  # LMS data and conversation context
    conversation_messages_analyzed = models.IntegerField()

    # Mentor Response
    suggestion_used = models.BooleanField(default=False)
    mentor_feedback = models.TextField(blank=True)  # Optional feedback from mentor
    effectiveness_rating = models.IntegerField(null=True)  # 1-5 rating from mentor

    # Suggestion Metadata
    ai_model_used = models.CharField(max_length=100)
    generation_time_ms = models.IntegerField()

    created_at = models.DateTimeField(auto_now_add=True)

    class Meta:
        db_table = 'zerver_ai_message_suggestion'

class ConversationContext(models.Model):
    """Store analyzed conversation context for AI processing"""

    realm = models.ForeignKey(Realm, on_delete=models.CASCADE)
    mentor = models.ForeignKey(UserProfile, on_delete=models.CASCADE, related_name='conversation_contexts_as_mentor')
    student = models.ForeignKey(UserProfile, on_delete=models.CASCADE, related_name='conversation_contexts_as_student')

    # Conversation Analysis
    recent_topics = models.JSONField(default=list)  # Topics discussed recently
    sentiment_trend = models.JSONField()  # Sentiment analysis over time
    question_patterns = models.JSONField()  # Types of questions being asked
    engagement_level = models.FloatField()  # Student engagement score

    # Academic Context
    current_academic_focus = models.JSONField()  # Subjects/topics currently being discussed
    help_request_frequency = models.FloatField()  # How often student asks for help
    meeting_request_patterns = models.JSONField()  # When/how student requests meetings

    # Temporal Context
    conversation_frequency = models.FloatField()  # Messages per week
    response_time_patterns = models.JSONField()  # How quickly mentor/student respond
    peak_communication_times = models.JSONField()  # When they communicate most

    # Context Metadata
    messages_analyzed_count = models.IntegerField()
    context_freshness_score = models.FloatField()  # How current the analysis is

    last_analysis_date = models.DateTimeField(auto_now=True)
    created_at = models.DateTimeField(auto_now_add=True)

    class Meta:
        db_table = 'zerver_conversation_context'
        unique_together = ('mentor', 'student')

class LMSDataAccessLog(models.Model):
    """Track LMS data access for compliance"""

    realm = models.ForeignKey(Realm, on_delete=models.CASCADE)
    accessing_user = models.ForeignKey(UserProfile, on_delete=models.CASCADE, related_name='lms_access_requests')
    target_user = models.ForeignKey(UserProfile, on_delete=models.CASCADE, related_name='lms_data_accessed')

    data_types_accessed = models.JSONField()  # ['courses', 'grades', 'assignments']
    access_reason = models.CharField(max_length=100)  # 'ai_message_enhancement', 'mentor_dashboard'

    success = models.BooleanField()
    error_message = models.TextField(null=True, blank=True)

    accessed_at = models.DateTimeField(auto_now_add=True)

    class Meta:
        db_table = 'zerver_lms_data_access_log'

class StudentAIPreferences(models.Model):
    """Student preferences for AI features"""

    user = models.OneToOneField(UserProfile, on_delete=models.CASCADE)

    ai_enhancement_enabled = models.BooleanField(default=True)
    lms_data_sharing_enabled = models.BooleanField(default=False)  # Explicit consent required

    preferred_ai_tone = models.CharField(
        max_length=20,
        choices=[
            ('formal', 'Formal/Academic'),
            ('friendly', 'Friendly/Casual'),
            ('encouraging', 'Encouraging/Supportive')
        ],
        default='encouraging'
    )

    ai_suggestion_types = models.JSONField(default=list)  # ['study_resources', 'schedule_help', 'performance_insights']

    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)

    class Meta:
        db_table = 'zerver_student_ai_preferences'
```

### 6. API Endpoints (Enhanced with Agent Support)

The API has been enhanced to support the new LangGraph agent system while maintaining backward compatibility:

```python
# zerver/views/ai_mentor_messages.py - Enhanced with agent support
from django.http import HttpRequest, HttpResponse
from zerver.decorator import require_realm_member
from zerver.lib.response import json_success, json_error
from zerver.lib.typed_endpoint import typed_endpoint
from zerver.models import UserProfile

#### New Agent-Powered Endpoints

**1. Get Intelligent Message Suggestions**
```python
@require_realm_member
@typed_endpoint
def get_intelligent_message_suggestions(
    request: HttpRequest,
    user_profile: UserProfile,
    *,
    student_user_id: int,
    message_content: str,
) -> HttpResponse:
    """Get AI-powered suggestions for mentor response using LangGraph agents"""

    # Enhanced with multi-agent processing
    ai_engine = AIMentorResponseEngine()
    suggestions = ai_engine.get_intelligent_suggestions(
        student=student,
        mentor=user_profile,
        message_content=message_content
    )

    return json_success({
        'suggestions': suggestions,
        'agent_system_used': ai_engine.use_agents,
        'suggestion_count': len(suggestions)
    })
```

**Response Format:**
```json
{
    "suggestions": [
        {
            "text": "Consider asking follow-up questions to understand their specific challenges",
            "type": "teaching_strategy",
            "priority": "high",
            "category": "questioning",
            "confidence": 0.9,
            "suggestion_id": "sug_1234567890_0"
        },
        {
            "text": "Share relevant learning resources about this topic",
            "type": "resource_guidance",
            "priority": "medium",
            "category": "resource_sharing",
            "confidence": 0.8,
            "suggestion_id": "sug_1234567890_1"
        }
    ],
    "student_id": 456,
    "suggestion_count": 2,
    "agent_system_used": true,
    "timestamp": "2024-01-15T10:30:00Z"
}
```

**2. Enhanced Message Enhancement**
```python
@require_realm_member
@typed_endpoint
def enhance_mentor_message(
    request: HttpRequest,
    user_profile: UserProfile,
    *,
    recipient_user_id: int,
    message_content: str,
    enhancement_type: str = "contextual",
) -> HttpResponse:
    """Enhance mentor message with AI using LangGraph agents"""

    # Process through agent system for comprehensive enhancement
    suggestions = ai_engine.get_intelligent_suggestions(...)

    return json_success({
        'original_message': message_content,
        'intelligent_suggestions': suggestions,
        'agent_system_used': True,
        'enhancement_available': len(suggestions) > 0
    })
```

#### Enhanced Existing Endpoints

**Updated Process Mentor Message Request**
```python
@require_realm_member
@typed_endpoint
def process_mentor_message_request(
    request: HttpRequest,
    user_profile: UserProfile,
    *,
    recipient_user_id: int,
    message_content: str,
    enable_ai_assistance: bool = True,
) -> HttpResponse:
    """Process student message with enhanced agent support"""

    # Now supports both agent and legacy processing
    ai_response = _process_ai_mentor_response(
        student=user_profile,
        mentor=mentor,
        student_message=message_content
    )

    return json_success({
        'message_id': message_id,
        'ai_response_sent': ai_response_sent,
        'agent_system_used': ai_engine.use_agents,
        'processing_method': 'langgraph_agents' if ai_engine.use_agents else 'legacy'
    })
```

**Enhanced Get Mentor AI Settings**

    from zerver.lib.ai_messaging import AIMessageEnhancer
    from zerver.lib.ai_privacy import AIPrivacyController
    from zerver.lib.lms_integration import LMSDataFetcher

    privacy_controller = AIPrivacyController()

    # Check permissions
    if not privacy_controller.can_access_ai_features(user_profile):
        return json_error("AI features not available for this user")

    # Get recipient
    try:
        recipient = UserProfile.objects.get(id=recipient_id, realm=user_profile.realm)
    except UserProfile.DoesNotExist:
        return json_error("Recipient not found")

    # Check if sender can communicate with recipient
    if not user_profile.can_communicate_with(recipient):
        return json_error("Not authorized to send messages to this user")

    # Fetch LMS context if permitted
    lms_context = None
    if privacy_controller.can_access_lms_data(user_profile, recipient):
        lms_fetcher = LMSDataFetcher()
        lms_context = lms_fetcher.get_student_context(recipient.id, recipient.realm.id)

    # Enhance message with AI
    enhancer = AIMessageEnhancer()
    enhancement = enhancer.enhance_mentor_message(
        sender=user_profile,
        recipient=recipient,
        original_content=message_content,
        lms_context=lms_context
    )

    return json_success({
        'enhanced_message': enhancement['enhanced_message'],
        'suggestions': enhancement['suggestions'],
        'confidence': enhancement['confidence'],
        'ai_used': enhancement['ai_used']
    })

@require_realm_member
@typed_endpoint
def get_ai_suggestions(
    request: HttpRequest,
    user_profile: UserProfile,
    *,
    recipient_id: int,
    message_context: str = ""
) -> HttpResponse:
    """Get AI-powered suggestions for messaging a specific user"""

    from zerver.lib.ai_messaging import AIMessageEnhancer
    from zerver.lib.lms_integration import LMSDataFetcher

    try:
        recipient = UserProfile.objects.get(id=recipient_id, realm=user_profile.realm)
    except UserProfile.DoesNotExist:
        return json_error("Recipient not found")

    # Get contextual suggestions based on recipient's role and LMS data
    suggestions = []

    if recipient.is_student and (user_profile.is_mentor or user_profile.is_faculty):
        # Get student-specific suggestions
        lms_fetcher = LMSDataFetcher()
        student_context = lms_fetcher.get_student_context(recipient.id, recipient.realm.id)

        if student_context:
            suggestions = generate_student_support_suggestions(student_context)
        else:
            suggestions = get_default_student_suggestions()

    return json_success({'suggestions': suggestions})

def generate_student_support_suggestions(student_context: dict) -> list:
    """Generate contextual suggestions for supporting a student"""

    suggestions = []

    # Course-specific suggestions
    current_courses = student_context.get('academic_status', {}).get('current_courses', [])
    for course in current_courses:
        suggestions.append({
            'type': 'course_support',
            'text': f"Ask about progress in {course}",
            'template': f"How are you finding {course} so far? Any particular topics you'd like to discuss?"
        })

    # Performance-based suggestions
    struggling_areas = student_context.get('learning_profile', {}).get('struggling_areas', [])
    for area in struggling_areas:
        suggestions.append({
            'type': 'academic_support',
            'text': f"Offer help with {area}",
            'template': f"I noticed you might benefit from some additional support with {area}. Would you like to schedule a study session?"
        })

    # General encouragement
    suggestions.append({
        'type': 'encouragement',
        'text': "Send encouragement",
        'template': "I wanted to check in and see how you're doing with your studies. Remember, I'm here to help if you need anything!"
    })

    return suggestions[:5]  # Limit to 5 suggestions

@require_realm_member
@typed_endpoint
def enable_ai_auto_reply(
    request: HttpRequest,
    user_profile: UserProfile,
    *,
    enabled: bool,
    delay_hours_business: int = 4,
    delay_hours_nonbusiness: int = 12,
    delay_hours_weekend: int = 24
) -> HttpResponse:
    """Enable/disable AI auto-reply for mentor when unavailable"""

    # Only mentors and faculty can enable auto-reply
    if not (user_profile.is_mentor or user_profile.is_faculty):
        return json_error("Auto-reply feature only available for mentors and faculty")

    # Update mentor's auto-reply preferences
    mentor_prefs, created = MentorAIPreferences.objects.get_or_create(
        mentor=user_profile,
        defaults={
            'ai_auto_reply_enabled': enabled,
            'response_delay_business_hours': delay_hours_business,
            'response_delay_nonbusiness_hours': delay_hours_nonbusiness,
            'response_delay_weekend': delay_hours_weekend
        }
    )

    if not created:
        mentor_prefs.ai_auto_reply_enabled = enabled
        mentor_prefs.response_delay_business_hours = delay_hours_business
        mentor_prefs.response_delay_nonbusiness_hours = delay_hours_nonbusiness
        mentor_prefs.response_delay_weekend = delay_hours_weekend
        mentor_prefs.save()

    return json_success({
        'ai_auto_reply_enabled': enabled,
        'delay_settings': {
            'business_hours': delay_hours_business,
            'nonbusiness_hours': delay_hours_nonbusiness,
            'weekend': delay_hours_weekend
        }
    })

@require_realm_member
@typed_endpoint
def get_mentor_style_analysis(
    request: HttpRequest,
    user_profile: UserProfile
) -> HttpResponse:
    """Get AI analysis of mentor's communication style"""

    if not (user_profile.is_mentor or user_profile.is_faculty):
        return json_error("Style analysis only available for mentors and faculty")

    try:
        style_analysis = MentorCommunicationStyle.objects.get(mentor=user_profile)

        return json_success({
            'style_analysis': {
                'tone': style_analysis.tone_analysis,
                'formality_level': style_analysis.formality_level,
                'average_response_length': style_analysis.average_response_length,
                'common_phrases': style_analysis.common_phrases,
                'confidence_score': style_analysis.style_confidence_score
            },
            'analysis_metadata': {
                'messages_analyzed': style_analysis.messages_analyzed_count,
                'last_analysis': style_analysis.last_analysis_date.isoformat(),
                'style_version': style_analysis.style_version
            }
        })

    except MentorCommunicationStyle.DoesNotExist:
        # Trigger style analysis
        from zerver.lib.ai_messaging import MentorStyleAnalyzer

        analyzer = MentorStyleAnalyzer()
        style_analysis = analyzer.analyze_and_save_mentor_style(user_profile)

        if style_analysis:
            return json_success({
                'style_analysis': style_analysis,
                'message': 'Style analysis completed'
            })
        else:
            return json_error("Insufficient message history for style analysis. Need at least 10 messages.")

@require_realm_member
@typed_endpoint
def trigger_ai_auto_reply(
    request: HttpRequest,
    user_profile: UserProfile,
    *,
    message_id: int
) -> HttpResponse:
    """Manually trigger AI auto-reply for a specific message (for testing/admin)"""

    # Only allow mentors to trigger auto-replies for their own messages
    # or realm admins to trigger for any mentor
    if not (user_profile.is_realm_admin or user_profile.is_mentor):
        return json_error("Insufficient permissions")

    try:
        from zerver.models import Message
        message = Message.objects.get(id=message_id, realm=user_profile.realm)

        # Verify this is a student -> mentor message
        if not message.recipient.type == Recipient.PERSONAL:
            return json_error("Auto-reply only works for direct messages")

        # Get the mentor who should respond
        mentor = message.recipient.userprofile_set.filter(
            models.Q(is_mentor=True) | models.Q(is_faculty=True)
        ).first()

        if not mentor:
            return json_error("No mentor found for this conversation")

        # Generate AI auto-reply
        from zerver.lib.ai_messaging import AIAutoReplyEngine

        auto_reply_engine = AIAutoReplyEngine()
        ai_response = auto_reply_engine.generate_mentor_style_response(
            student_message=message.content,
            mentor=mentor,
            conversation_history=get_conversation_history(message.sender, mentor),
            student_context=get_student_lms_context(message.sender)
        )

        # Send the AI-generated response
        from zerver.lib.actions import send_personal_message

        send_personal_message(
            sender=mentor,
            recipient=message.sender,
            content=ai_response
        )

        # Log the auto-reply
        AIAutoReply.objects.create(
            realm=user_profile.realm,
            original_message=message,
            mentor=mentor,
            student=message.sender,
            ai_response_content=ai_response,
            mentor_style_used=auto_reply_engine.get_style_used(),
            response_delay_hours=0,  # Manual trigger
            ai_model_used="gpt-4",
            disclaimer_shown=True,
            mentor_notified=True
        )

        return json_success({
            'ai_response_sent': True,
            'response_content': ai_response,
            'mentor': mentor.full_name
        })

    except Message.DoesNotExist:
        return json_error("Message not found")

@require_realm_member
@typed_endpoint
def get_conversation_ai_insights(
    request: HttpRequest,
    user_profile: UserProfile,
    *,
    student_id: int
) -> HttpResponse:
    """Get AI insights about a specific mentor-student conversation"""

    # Only mentors can get insights about their students
    if not (user_profile.is_mentor or user_profile.is_faculty):
        return json_error("Conversation insights only available for mentors")

    try:
        student = UserProfile.objects.get(id=student_id, realm=user_profile.realm)

        # Verify mentor can communicate with this student
        if not user_profile.can_communicate_with(student):
            return json_error("No permission to view this student's data")

        # Get conversation context
        try:
            context = ConversationContext.objects.get(
                mentor=user_profile,
                student=student
            )

            insights = {
                'conversation_analysis': {
                    'recent_topics': context.recent_topics,
                    'engagement_level': context.engagement_level,
                    'help_request_frequency': context.help_request_frequency,
                    'communication_frequency': context.conversation_frequency
                },
                'academic_context': {
                    'current_focus': context.current_academic_focus,
                    'meeting_patterns': context.meeting_request_patterns
                },
                'ai_recommendations': self.generate_mentor_recommendations(context),
                'metadata': {
                    'last_analysis': context.last_analysis_date.isoformat(),
                    'messages_analyzed': context.messages_analyzed_count,
                    'context_freshness': context.context_freshness_score
                }
            }

            return json_success(insights)

        except ConversationContext.DoesNotExist:
            # Generate fresh context analysis
            from zerver.lib.ai_messaging import ConversationContextAnalyzer

            analyzer = ConversationContextAnalyzer()
            context = analyzer.analyze_and_save_context(user_profile, student)

            return json_success({
                'message': 'Context analysis completed',
                'insights': context
            })

    except UserProfile.DoesNotExist:
        return json_error("Student not found")

def generate_mentor_recommendations(context: ConversationContext) -> List[Dict]:
    """Generate AI recommendations for mentor based on conversation context"""

    recommendations = []

    # Low engagement recommendations
    if context.engagement_level < 0.5:
        recommendations.append({
            'type': 'engagement',
            'priority': 'high',
            'suggestion': 'Student engagement is low. Consider scheduling a check-in meeting.',
            'actions': ['schedule_meeting', 'send_encouraging_message']
        })

    # High help frequency recommendations
    if context.help_request_frequency > 2.0:  # More than 2 help requests per week
        recommendations.append({
            'type': 'academic_support',
            'priority': 'high',
            'suggestion': 'Student frequently requests help. Consider additional resources or study sessions.',
            'actions': ['provide_study_resources', 'schedule_regular_sessions']
        })

    # Communication pattern recommendations
    if context.conversation_frequency < 1.0:  # Less than 1 message per week
        recommendations.append({
            'type': 'communication',
            'priority': 'medium',
            'suggestion': 'Low communication frequency. Reach out proactively.',
            'actions': ['send_check_in_message', 'schedule_regular_check_ins']
        })

    return recommendations
```

### 7. Frontend Integration

```typescript
// web/src/ai_messaging.ts
import * as channel from "./channel";

interface AIEnhancement {
    enhanced_message: string;
    suggestions: string[];
    confidence: number;
    ai_used: boolean;
}

interface AISuggestion {
    type: string;
    text: string;
    template: string;
}

export class AIMessagingController {

    static enhance_message(
        recipient_id: number,
        message_content: string,
        enhancement_type: string = "contextual"
    ): Promise<AIEnhancement> {
        return channel.post({
            url: "/json/ai/enhance_message",
            data: {
                recipient_id: recipient_id,
                message_content: message_content,
                enhancement_type: enhancement_type
            }
        });
    }

    static get_ai_suggestions(recipient_id: number): Promise<AISuggestion[]> {
        return channel.get({
            url: "/json/ai/suggestions",
            data: { recipient_id: recipient_id }
        });
    }

    static show_ai_enhancement_ui(compose_state: any): void {
        // Show AI enhancement options in compose box
        const ai_panel = document.getElementById("ai-enhancement-panel");
        if (ai_panel && !user_settings.hide_ai_features) {
            ai_panel.style.display = "block";
            this.load_ai_suggestions(compose_state.private_message_recipient);
        }
    }

    static load_ai_suggestions(recipient_id: number): void {
        if (!recipient_id) return;

        this.get_ai_suggestions(recipient_id).then((suggestions) => {
            this.render_ai_suggestions(suggestions);
        }).catch((error) => {
            console.error("Failed to load AI suggestions:", error);
        });
    }

    static render_ai_suggestions(suggestions: AISuggestion[]): void {
        const container = document.getElementById("ai-suggestions-container");
        if (!container) return;

        container.innerHTML = suggestions.map(suggestion => `
            <div class="ai-suggestion" data-template="${suggestion.template}">
                <span class="ai-suggestion-type">${suggestion.type}</span>
                <span class="ai-suggestion-text">${suggestion.text}</span>
            </div>
        `).join('');

        // Add click handlers
        container.querySelectorAll('.ai-suggestion').forEach(element => {
            element.addEventListener('click', (e) => {
                const template = (e.currentTarget as HTMLElement).dataset.template;
                if (template) {
                    this.insert_ai_template(template);
                }
            });
        });
    }

    static insert_ai_template(template: string): void {
        const compose_textarea = document.getElementById("compose-textarea") as HTMLTextAreaElement;
        if (compose_textarea) {
            compose_textarea.value = template;
            compose_textarea.focus();
        }
    }
}
```

```handlebars
{{!-- web/templates/compose_ai_enhancement.hbs --}}
<div id="ai-enhancement-panel" class="ai-enhancement-panel" style="display: none;">
    <div class="ai-enhancement-header">
        <i class="fa fa-magic" aria-hidden="true"></i>
        <span>AI Message Enhancement</span>
        <button class="ai-enhancement-toggle btn btn-sm" data-toggle="collapse" data-target="#ai-suggestions-container">
            <i class="fa fa-chevron-down" aria-hidden="true"></i>
        </button>
    </div>

    <div id="ai-suggestions-container" class="ai-suggestions-container collapse in">
        <!-- AI suggestions will be populated here -->
    </div>

    <div class="ai-enhancement-actions">
        <button class="btn btn-sm btn-primary" id="enhance-message-btn">
            <i class="fa fa-wand-magic" aria-hidden="true"></i>
            Enhance with AI
        </button>
        <button class="btn btn-sm btn-secondary" id="get-suggestions-btn">
            <i class="fa fa-lightbulb" aria-hidden="true"></i>
            Get Suggestions
        </button>
    </div>
</div>

<style>
.ai-enhancement-panel {
    border: 1px solid #e0e0e0;
    border-radius: 4px;
    margin: 8px 0;
    background: #f9f9f9;
}

.ai-enhancement-header {
    padding: 8px 12px;
    background: #f0f8ff;
    border-bottom: 1px solid #e0e0e0;
    display: flex;
    align-items: center;
    gap: 8px;
    font-weight: 500;
}

.ai-suggestions-container {
    padding: 8px;
    max-height: 200px;
    overflow-y: auto;
}

.ai-suggestion {
    padding: 6px 8px;
    margin: 4px 0;
    border: 1px solid #ddd;
    border-radius: 3px;
    cursor: pointer;
    background: white;
    transition: background-color 0.2s;
}

.ai-suggestion:hover {
    background: #f0f8ff;
}

.ai-suggestion-type {
    font-size: 0.8em;
    color: #666;
    text-transform: uppercase;
    font-weight: 500;
}

.ai-suggestion-text {
    display: block;
    margin-top: 2px;
}

.ai-enhancement-actions {
    padding: 8px;
    border-top: 1px solid #e0e0e0;
    display: flex;
    gap: 8px;
}
</style>
```

## Configuration and Settings

### 1. Current Production Configuration

The AI agent system is configured through `zproject/ai_agent_settings.py` and integrated into the main settings system via `zproject/computed_settings.py`.

**Core Environment Variables:**
```bash
# Essential Configuration
USE_LANGGRAPH_AGENTS=true                           # Enable AI agent system
PORTKEY_API_KEY=your_portkey_api_key               # Portkey authentication

# AI Model Settings
AI_MENTOR_MODEL=gpt-4                              # LLM model selection
AI_MENTOR_TEMPERATURE=0.7                          # Response creativity
AI_MENTOR_MAX_TOKENS=1000                          # Maximum response length

# Decision Thresholds (Minutes-Based)
AI_MENTOR_MIN_ABSENCE_MINUTES=240                  # 4 hours before AI responds
AI_MENTOR_MAX_DAILY_RESPONSES=3                    # Daily response limit
AI_MENTOR_URGENCY_THRESHOLD=0.7                    # Urgency score threshold
AI_MENTOR_CONFIDENCE_THRESHOLD=0.6                 # Confidence threshold

# System Performance
AI_MENTOR_MAX_RETRIES=3                            # Retry attempts
AI_MENTOR_TIMEOUT=30                               # Request timeout (seconds)
AI_AGENT_STATE_DB_PATH=/var/lib/zulip/ai_agent_state.db  # State persistence
```

**Production Settings Integration:**
```python
# zproject/computed_settings.py - AI agent settings are automatically imported
try:
    from .ai_agent_settings import *  # noqa: F403

    # Validation and logging for production
    if globals().get('USE_LANGGRAPH_AGENTS', False):
        validation_warnings = globals().get('validate_ai_agent_settings', lambda: [])()
        if validation_warnings:
            logger.warning(f"AI Agent Configuration Warning: {warning}")

except ImportError:
    USE_LANGGRAPH_AGENTS = False
```

**See Also:** [Complete Environment Variables Guide](../production/ai-agent-environment-variables.md)

### 2. Agent Workflow Configuration

```python
# Fine-tune individual agent behavior
AI_AGENT_WORKFLOW_CONFIG = {
    'style_analysis': {
        'min_messages_required': 5,
        'max_messages_analyzed': 50,
        'cache_duration_hours': 24,
    },
    'context_analysis': {
        'conversation_history_limit': 10,
        'urgency_keywords_weight': 0.8,
    },
    'response_generation': {
        'candidate_variants': 3,
        'quality_threshold': 0.7,
    },
    'suggestion_generation': {
        'max_suggestions': 5,
        'suggestion_categories': [
            'content_recommendations',
            'tone_adjustments',
            'resource_suggestions',
            'follow_up_actions',
            'teaching_strategies'
        ],
    }
}
```

### 3. Feature Flags for Gradual Rollout

```python
# Enable/disable specific agent features
AI_AGENT_FEATURE_FLAGS = {
    'enable_style_analysis': True,
    'enable_context_analysis': True,
    'enable_response_generation': True,
    'enable_intelligent_suggestions': True,
    'enable_auto_responses': True,
}
```

### 4. Legacy Django Settings (Fallback)

```python
# zproject/settings.py - Legacy settings still supported

# AI Integration Settings (Legacy)
AI_FEATURES_ENABLED = True
TOPIC_SUMMARIZATION_MODEL = "gpt-4"  # Used for AI feature detection
AI_MAX_TOKENS = 500
AI_TEMPERATURE = 0.7

# LMS Integration Settings
LMS_INTEGRATION_ENABLED = True
LMS_DATABASE_CONFIG = {
    'ENGINE': 'django.db.backends.postgresql',
    'NAME': 'lms_readonly',
    'HOST': get_secret("lms_db_host"),
    'PORT': 5432,
    'USER': 'readonly_user',
    'PASSWORD': get_secret("lms_db_password"),
    'OPTIONS': {
        'sslmode': 'require',
        'connect_timeout': 10,
        'options': '-c default_transaction_isolation=serializable'
    }
}

# Privacy and Security
AI_CONTENT_FILTERING_ENABLED = True
AI_AUDIT_LOGGING_ENABLED = True
LMS_DATA_RETENTION_DAYS = 30
AI_INTERACTION_LOG_RETENTION_DAYS = 90

# Feature Flags per Plan Type
AI_FEATURES_BY_PLAN = {
    Realm.PLAN_TYPE_LIMITED: {
        'ai_enhancement': False,
        'lms_integration': False,
        'max_ai_requests_per_day': 0
    },
    Realm.PLAN_TYPE_STANDARD: {
        'ai_enhancement': True,
        'lms_integration': False,
        'max_ai_requests_per_day': 50
    },
    Realm.PLAN_TYPE_PLUS: {
        'ai_enhancement': True,
        'lms_integration': True,
        'max_ai_requests_per_day': 200
    }
}
```

### 2. Realm-Level Settings

```python
# Add to zerver/models/realms.py
class Realm(models.Model):
    # ... existing fields ...

    # AI Feature Settings
    ai_features_enabled = models.BooleanField(default=False)
    ai_message_enhancement_enabled = models.BooleanField(default=False)
    lms_integration_enabled = models.BooleanField(default=False)

    # LMS Configuration
    lms_database_identifier = models.CharField(max_length=100, blank=True)
    lms_data_sharing_agreement_date = models.DateTimeField(null=True, blank=True)

    def can_use_ai_features(self) -> bool:
        """Check if realm can use AI features based on plan and settings"""
        if not self.ai_features_enabled:
            return False

        plan_config = settings.AI_FEATURES_BY_PLAN.get(self.plan_type, {})
        return plan_config.get('ai_enhancement', False)

    def can_use_lms_integration(self) -> bool:
        """Check if realm can use LMS integration"""
        if not self.lms_integration_enabled:
            return False

        plan_config = settings.AI_FEATURES_BY_PLAN.get(self.plan_type, {})
        return plan_config.get('lms_integration', False)
```

## Security and Compliance

### 1. Data Privacy Measures

- **Realm Isolation**: All AI enhancements respect Zulip's realm boundaries
- **Role-Based Access**: AI features only work within existing communication permissions
- **Explicit Consent**: Students must opt-in to LMS data sharing
- **Data Minimization**: Only necessary LMS data is accessed and cached temporarily
- **Audit Trail**: Complete logging of all AI interactions and LMS data access

### 2. Content Safety

- **Educational Filter**: AI responses filtered for educational appropriateness
- **Harmful Content Detection**: Multiple layers of content safety checks
- **Human Oversight**: Option for manual review of AI suggestions
- **Fallback Mechanisms**: Safe defaults when AI processing fails

### 3. External System Security

- **Read-Only Access**: LMS database access is strictly read-only
- **Connection Security**: All external connections use TLS encryption
- **Access Logging**: Complete audit trail of external data access
- **Rate Limiting**: Protection against excessive API usage

## Deployment Strategy

### 1. Dependencies and Requirements

**Install Agent System Dependencies:**
```bash
# Install all Zulip dependencies including LangGraph agents
pip install -e .

# Core AI agent dependencies included:
# - langgraph>=0.2.16
# - langchain-core>=0.3.0
# - langchain-openai>=0.2.0
# - portkey-ai>=1.8.0
```

**Environment Variables:**
```bash
# Required for agent system
export USE_LANGGRAPH_AGENTS=true
export PORTKEY_API_KEY=your_portkey_api_key

# Optional configuration
export AI_MENTOR_MODEL=gpt-4
export AI_MENTOR_MIN_ABSENCE_MINUTES=240  # 4 hours = 240 minutes
export AI_MENTOR_MAX_DAILY_RESPONSES=3
export AI_MENTOR_CONFIDENCE_THRESHOLD=0.6
```

### 2. Gradual Rollout Plan (Enhanced)

**Phase 1: Agent Infrastructure Setup**
- âœ… Install LangGraph and Portkey dependencies
- âœ… Configure agent system settings
- âœ… Set up SQLite state persistence
- âœ… Enable hybrid fallback mechanism
- âœ… Implement comprehensive logging

**Phase 2: Limited Agent Deployment**
- Enable agents for specific mentors (feature flag)
- A/B test agent vs legacy responses
- Monitor performance and quality metrics
- Collect user feedback on AI suggestions

**Phase 3: Full Agent Rollout**
- Enable agents for all mentors
- Deploy intelligent suggestions system
- Enable advanced context analysis
- Implement Portkey observability

**Phase 4: Advanced Features**
- Enable LMS data integration with agents
- Deploy multi-modal style analysis
- Implement advanced analytics dashboard
- Optimize performance and cost

### 3. Monitoring and Validation

**Agent System Health Checks:**
```python
# Validate agent system configuration
from zproject.ai_agent_settings import validate_ai_agent_settings

def check_agent_system_health():
    warnings = validate_ai_agent_settings()
    if warnings:
        logger.warning(f"Agent system warnings: {warnings}")

    # Test agent workflow
    orchestrator = create_ai_agent_orchestrator()
    result = orchestrator.process_student_message(
        student_id=test_student_id,
        mentor_id=test_mentor_id,
        message_content="Test message"
    )

    return result["success"]
```

**Performance Monitoring:**
- Agent processing time (<3 seconds target)
- Portkey API response times and error rates
- Token usage and cost tracking
- User satisfaction scores
- System fallback frequency

### 2. Monitoring and Metrics

```python
# Metrics to track
ai_messaging_metrics = {
    'enhancement_requests_per_day': 'Count of AI enhancement requests',
    'enhancement_success_rate': 'Percentage of successful AI enhancements',
    'lms_data_fetch_success_rate': 'Percentage of successful LMS data fetches',
    'user_satisfaction_score': 'User feedback on AI suggestions quality',
    'content_filter_trigger_rate': 'Rate of content filtering activation',
    'average_response_time': 'AI enhancement processing time',
    'feature_adoption_rate': 'Percentage of users using AI features'
}
```

## Testing Strategy

The spike test in `/Users/straxs/Work/zulip/zerver/tests/test_ai_messaging_integration.py` covers:

1. **Core Functionality Testing**
   - Mentor-student communication validation
   - AI message enhancement workflow
   - LMS data integration

2. **Security Testing**
   - Realm isolation verification
   - Cross-tenant data protection
   - Permission validation

3. **Content Safety Testing**
   - AI response filtering
   - Educational appropriateness validation

4. **Integration Testing**
   - External LMS database connectivity
   - API endpoint functionality
   - Error handling and fallbacks

5. **Audit and Compliance Testing**
   - Logging verification
   - Privacy control validation
   - Data retention compliance

## Future Enhancements

1. **Advanced AI Features**
   - Sentiment analysis for early intervention
   - Predictive analytics for at-risk students
   - Automated study group formation

2. **Enhanced LMS Integration**
   - Real-time grade synchronization
   - Assignment deadline reminders
   - Calendar integration

3. **Mobile App Support**
   - Native mobile AI features
   - Offline AI suggestions
   - Push notification enhancements

4. **Analytics Dashboard**
   - AI usage analytics
   - Student engagement metrics
   - Mentor effectiveness tracking

## Conclusion

This integrated AI messaging app builds upon Zulip's strong foundation of role-based communication and realm isolation to provide intelligent educational support. The architecture ensures privacy, security, and compliance while delivering powerful AI-enhanced communication capabilities for educational environments.

The system is designed to be:
- **Secure by default**: Respects all existing Zulip security boundaries
- **Privacy-focused**: Explicit consent and data minimization
- **Educationally appropriate**: Content filtering and safety measures
- **Scalable**: Can handle large educational institutions
- **Compliant**: Audit trails and data governance features

The spike test validates the core architecture and provides a foundation for iterative development and deployment of this advanced educational communication platform.